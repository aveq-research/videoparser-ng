<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.15.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>VideoParser: Developer Guide</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript" src="../../clipboard.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">VideoParser<span id="projectnumber">&#160;0.2.0</span>
   </div>
   <div id="projectbrief">C++ Video Bitstream Parsing Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.15.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('d0/dc5/md_DEVELOPERS.html','../../',''); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Developer Guide </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md21"></a></p>
<p>Contents:</p>
<ul>
<li>General Structure</li>
<li>Modifications Made<ul>
<li>QP Information</li>
<li>Motion Vector Information</li>
<li>AV1 / libaom Specific Changes</li>
</ul>
</li>
<li>Metrics<ul>
<li>QP Metrics</li>
<li>Motion Vector Metrics</li>
<li>Bit Count Metrics</li>
<li>Block Count Metrics</li>
<li>POC Metrics</li>
<li>Frame Metadata</li>
</ul>
</li>
<li>Differences with Legacy Implementation<ul>
<li>All Codecs: POC-based Motion Vector Normalization</li>
<li>VP9: Motion Statistics for All Inter Modes</li>
<li>VP9: Motion Bit Count</li>
<li>VP9: Removed Weighted Variance Accumulation</li>
<li>All Codecs: Removed Arbitrary Scaling Factors</li>
</ul>
</li>
<li>Testing<ul>
<li>Feature Testing</li>
<li>Regenerating Test Reference Files</li>
<li>Legacy Testing</li>
<li>CLI Testing</li>
</ul>
</li>
<li>Debugging</li>
<li>Maintenance<ul>
<li>Fetching new FFmpeg commits</li>
<li>Fetching new libaom commits</li>
</ul>
</li>
<li>Black Border Implementation Notes<ul>
<li>Algorithm Details</li>
<li>1. BlackLine Array Population (Per-Codec)</li>
</ul>
</li>
</ul>
<h1 class="doxsection"><a class="anchor" id="autotoc_md22"></a>
General Structure</h1>
<p>This program patches ffmpeg to add support for extracting additional bitstream properties, or codec-related information, from the bitstream. The program is structured as follows:</p>
<ul>
<li><span class="tt">VideoParser</span> is an API that provides a simple interface for extracting bitstream properties from a video file. It is implemented as a basic frame-by-frame reader that itself is using ffmpeg standard API calls to read the video.</li>
<li>VideoParserCli is a command-line interface for VideoParser. It is implemented by using VideoParser API calls to extract the bitstream properties, and then printing them to the console in JSON format.</li>
<li>ffmpeg is cloned and has a separate branch checked out.</li>
<li><span class="tt">libaom</span> is also cloned and has a separate branch checked out, with modifications to support the extraction of bitstream properties.</li>
</ul>
<p>To pass extra information from the ffmpeg part to the VideoParser part, we use the <span class="tt">SharedFrameInfo</span> struct to store the bitstream properties like QP values, motion vectors, etc. The definition is in <span class="tt">VideoParser/include/shared.h</span>, and it is included in ffmpeg as well, via an extra side data type <span class="tt">AV_FRAME_DATA_VIDEOPARSER_INFO</span>.</p>
<p>It is extracted from there using a helper function <span class="tt">videoparser_get_final_shared_frame_info</span>. This is implemented in <span class="tt">ffmpeg/libavutil/frame.c</span> as an additional method. It performs some extra calculations on the data, like average QP, standard deviation, etc.</p>
<p>To update the data, we have helper functions like <span class="tt">videoparser_shared_frame_info_update_qp</span>.</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md23"></a>
Modifications Made</h1>
<p>This explains the high level changes made to ffmpeg to support the extraction of bitstream properties.</p>
<p>All modifications are marked with <span class="tt">// videoparser:</span> comments for easy identification.</p>
<p>We have modified <span class="tt">decode.c</span> to extract the frame index (method <span class="tt">ff_decode_receive_frame</span>).</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md24"></a>
QP Information</h2>
<p>To obtain the QP information, we modify:</p>
<ul>
<li>H.264: <span class="tt">h264_mb.c</span>, to extract the QP information from the <span class="tt">H264SliceContext</span> struct, in the function <span class="tt">ff_h264_hl_decode_mb</span></li>
<li>HEVC: <span class="tt">hevcdec.c</span>, to extract the QP information from the <span class="tt">HEVCLocalContext</span> struct, in the function <span class="tt">hls_coding_unit</span></li>
<li>VP9: <span class="tt">vp9.c</span>, to extract the QP information from the <span class="tt">VP9SharedContext</span> struct, in the function <span class="tt">vp9_decode_frame</span></li>
<li>AV1: <span class="tt">libaomdec.c</span>, to extract the QP information from the <span class="tt">AV1DecodeContext</span> struct, in the function <span class="tt">aom_decode</span></li>
</ul>
<h2 class="doxsection"><a class="anchor" id="autotoc_md25"></a>
Motion Vector Information</h2>
<p>To obtain motion vector information, we modify:</p>
<ul>
<li>H.264: <span class="tt">h264_mb.c</span>, via <span class="tt">mv_statistics_264</span> function</li>
<li>HEVC: <span class="tt">hevcdec.c</span>, via <span class="tt">mv_statistics_hevc</span> function</li>
<li>VP9: <span class="tt">vp9mvs.c</span>, via <span class="tt">mv_statistics_vp9</span> function</li>
<li>AV1: <span class="tt">libaomdec.c</span>, via <span class="tt">videoparser_av1_extract_mv_stats</span> function using libaom's inspection API</li>
</ul>
<h2 class="doxsection"><a class="anchor" id="autotoc_md26"></a>
AV1 / libaom Specific Changes</h2>
<p>For AV1 support, we use a vendored copy of libaom built with <span class="tt">CONFIG_INSPECTION=1</span> to enable the inspection API. The inspection API provides access to internal decoder state including per-block mode info and motion vectors.</p>
<p>Key modifications:</p>
<ul>
<li><span class="tt">util/build-libaom.sh</span>: Configured with <span class="tt">-DCONFIG_INSPECTION=1</span> to enable inspection API</li>
<li><span class="tt">external/libaom/av1/av1_dx_iface.c</span>: Modified <span class="tt">decode_one()</span> to propagate the inspection callback to the decoder instance (the stock code only did this in <span class="tt">decoder_inspect()</span> which FFmpeg doesn't use)</li>
<li><span class="tt">external/ffmpeg/libavcodec/libaomdec.c</span>: Added inspection callback setup and MV/MVD/bit count extraction function</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md27"></a>
MVD and Bit Count Extraction</h3>
<p>To extract motion vector differences (MVD) and bit counts for AV1, additional modifications were made to libaom:</p>
<ul>
<li><span class="tt">external/libaom/av1/common/blockd.h</span>: Added <span class="tt">mvd[2]</span> field to <span class="tt">MB_MODE_INFO</span> struct under <span class="tt">CONFIG_INSPECTION</span> to store motion vector differences during decoding</li>
<li><span class="tt">external/libaom/av1/decoder/decoder.h</span>: Added <span class="tt">motion_bits</span> and <span class="tt">coef_bits</span> accumulators to <span class="tt">AV1Decoder</span> and <span class="tt">ThreadData</span> structs</li>
<li><span class="tt">external/libaom/av1/decoder/inspection.h</span>: Added <span class="tt">mvd[2]</span> to <span class="tt">insp_mi_data</span> and <span class="tt">motion_bits</span>/<span class="tt">coef_bits</span> to <span class="tt">insp_frame_data</span></li>
<li><span class="tt">external/libaom/av1/decoder/inspection.c</span>: Added copying of MVD and bit counts in <span class="tt">ifd_inspect()</span></li>
<li><span class="tt">external/libaom/av1/decoder/decodemv.c</span>: Store MVD in <span class="tt">mbmi-&gt;mvd[]</span> for all NEWMV modes in <span class="tt">assign_mv()</span>, and track motion bits using <span class="tt">aom_reader_tell_frac()</span> around MV decoding</li>
<li><span class="tt">external/libaom/av1/decoder/decodeframe.c</span>: Track coefficient bits around intra/inter coefficient decoding using <span class="tt">aom_reader_tell_frac()</span>, reset counters at frame start in <span class="tt">av1_decode_frame_headers_and_setup()</span></li>
</ul>
<h1 class="doxsection"><a class="anchor" id="autotoc_md28"></a>
Metrics</h1>
<p>This section documents the per-frame metrics extracted by the video parser.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md29"></a>
QP Metrics</h2>
<p>QP (Quantization Parameter) values are codec-specific indices that control quantization strength. Higher values mean more compression/lower quality. Typical ranges: H.264/HEVC: 0–51, VP9: 0–255, AV1: 0–255.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md30"></a>
qp_avg</h3>
<p>Average QP of all coding units in the frame. Unit: QP index (dimensionless).</p>
<ul>
<li><b>H.264</b>: Extracted per macroblock in <span class="tt">h264_mb.c</span>. Accumulated via <span class="tt">qp_sum</span> and <span class="tt">qp_cnt</span>. Range: 0–51.</li>
<li><b>HEVC</b>: Extracted per coding unit in <span class="tt">hevcdec.c</span>. Range: 0–51.</li>
<li><b>VP9</b>: Extracted per frame in <span class="tt">vp9.c</span>. Range: 0–255. Note: not yet implemented for segmented streams.</li>
<li><b>AV1</b>: Extracted via libaom in <span class="tt">libaomdec.c</span>. Range: 0–255.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md31"></a>
qp_stdev</h3>
<p>Standard deviation of QP values within a frame. Unit: QP index (dimensionless).</p>
<ul>
<li><b>H.264</b>: Computed from <span class="tt">qp_sum_sqr</span> using variance formula.</li>
<li><b>HEVC</b>: Same method as H.264.</li>
<li><b>VP9</b>: Not yet implemented for segmented streams.</li>
<li><b>AV1</b>: Computed via libaom.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md32"></a>
qp_min</h3>
<p>Minimum QP value encountered in the frame. Unit: QP index (dimensionless).</p>
<ul>
<li><b>H.264</b>: Updated during macroblock processing.</li>
<li><b>HEVC</b>: Updated during coding unit processing.</li>
<li><b>VP9</b>: Not yet implemented for segmented streams.</li>
<li><b>AV1</b>: Extracted via libaom.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md33"></a>
qp_max</h3>
<p>Maximum QP value encountered in the frame. Unit: QP index (dimensionless).</p>
<ul>
<li><b>H.264</b>: Updated during macroblock processing.</li>
<li><b>HEVC</b>: Updated during coding unit processing.</li>
<li><b>VP9</b>: Not yet implemented for segmented streams.</li>
<li><b>AV1</b>: Extracted via libaom.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md34"></a>
qp_init</h3>
<p>Initial QP value from slice or frame header. Unit: QP index (dimensionless).</p>
<ul>
<li><b>H.264</b>: Extracted from slice header.</li>
<li><b>HEVC</b>: Extracted from slice header.</li>
<li><b>VP9</b>: Not yet implemented for segmented streams.</li>
<li><b>AV1</b>: Extracted via libaom.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md35"></a>
qp_bb_avg</h3>
<p>Average QP excluding black border regions (letterbox areas). Unit: QP index (dimensionless).</p>
<p><b>Work in progress for all codecs.</b></p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md36"></a>
qp_bb_stdev</h3>
<p>Standard deviation of QP excluding black border regions. Unit: QP index (dimensionless).</p>
<p><b>Work in progress for all codecs.</b></p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md37"></a>
Motion Vector Metrics</h2>
<p>Motion vector metrics are in codec-native sub-pel units:</p>
<ul>
<li><b>H.264/HEVC</b>: Quarter-pel (1/4 pixel). Divide by 4 for full-pel values.</li>
<li><b>VP9/AV1</b>: Eighth-pel (1/8 pixel). Divide by 8 for full-pel values.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md38"></a>
motion_avg</h3>
<p>Average motion vector length per frame, computed as the mean of <span class="tt">sqrt(mv_x² + mv_y²)</span> over all motion vectors.</p>
<ul>
<li><b>H.264</b>: Extracted in <span class="tt">h264_mb.c</span> via <span class="tt">mv_statistics_264</span>. Motion vectors are collected from both L0 (forward) and L1 (backward) reference lists. For bi-directional blocks, values from both directions are averaged. By default, raw motion vector values are used. A compile-time flag <span class="tt">VP_MV_POC_NORMALIZATION</span> can be set to <span class="tt">1</span> to enable POC-based normalization, which weighs motion vectors by temporal distance to their reference frames.</li>
<li><b>HEVC</b>: Extracted in <span class="tt">hevcdec.c</span> via <span class="tt">mv_statistics_hevc</span>. Motion vectors are collected from L0 and L1 prediction lists. For bi-predictive blocks, values from both directions are averaged. Raw MV values without POC normalization.</li>
<li><b>VP9</b>: Extracted in <span class="tt">vp9mvs.c</span> via <span class="tt">mv_statistics_vp9</span>. Motion vectors are collected after prediction in <span class="tt">ff_vp9_fill_mv</span>. For compound (bi-predictive) mode, values from both references are averaged. Raw MV values.</li>
<li><b>AV1</b>: Extracted in <span class="tt">libaomdec.c</span> via <span class="tt">videoparser_av1_extract_mv_stats</span> using libaom's inspection API. Motion vectors are collected from all inter blocks (mode &gt;= NEARESTMV). For compound prediction, values from L0 and L1 references are averaged. Raw MV values in 1/8 pel units.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md39"></a>
motion_stdev</h3>
<p>Standard deviation of motion vector lengths within a frame.</p>
<p>This is computed from <span class="tt">mv_sum_sqr</span> accumulated during motion vector extraction.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md40"></a>
motion_x_avg</h3>
<p>Average of the absolute X (horizontal) components of motion vectors.</p>
<p>This is accumulated separately from Y components using <span class="tt">fabs()</span> to ensure positive contributions.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md41"></a>
motion_y_avg</h3>
<p>Average of the absolute Y (vertical) components of motion vectors.</p>
<p>Same accumulation method as <span class="tt">motion_x_avg</span>, but for vertical motion.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md42"></a>
motion_x_stdev</h3>
<p>Standard deviation of the X components of motion vectors.</p>
<p>Computed from <span class="tt">mv_x_sum_sqr</span>.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md43"></a>
motion_y_stdev</h3>
<p>Standard deviation of the Y components of motion vectors.</p>
<p>Computed from <span class="tt">mv_y_sum_sqr</span>.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md44"></a>
motion_diff_avg</h3>
<p>Average motion vector prediction residual length. Represents the difference between the actual motion vector and its predicted value (MVD).</p>
<ul>
<li><b>H.264</b>: Extracted from <span class="tt">motion_diff_L0</span> and <span class="tt">motion_diff_L1</span> arrays. Values stored as unsigned 8-bit integers; values &gt; 127 are interpreted as negative (two's complement).</li>
<li><b>HEVC</b>: Extracted from <span class="tt">MvField.mvd</span> which contains the coded motion vector difference.</li>
<li><b>VP9</b>: Extracted from coded MVD components for NEWMV mode only. For NEARESTMV/NEARMV modes (which use predicted MVs without coded residuals), MVD is zero.</li>
<li><b>AV1</b>: Extracted via modified libaom decoder. MVD is captured during <span class="tt">assign_mv()</span> in <span class="tt">decodemv.c</span> by computing the difference between final MV and reference MV for NEWMV modes. Stored in <span class="tt">mbmi-&gt;mvd[]</span> and exposed through the inspection API. For compound modes with one NEWMV reference, only that reference's MVD is non-zero.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md45"></a>
motion_diff_stdev</h3>
<p>Standard deviation of motion vector prediction residuals.</p>
<p>Computed from <span class="tt">mv_diff_sum_sqr</span>.</p>
<ul>
<li><b>AV1</b>: Note: MVD values from the inspection API are accumulated in <span class="tt">libaomdec.c</span>.</li>
</ul>
<h2 class="doxsection"><a class="anchor" id="autotoc_md46"></a>
Bit Count Metrics</h2>
<h3 class="doxsection"><a class="anchor" id="autotoc_md47"></a>
motion_bit_count</h3>
<p>Number of bits used for coding motion information in the frame. Unit: bits.</p>
<ul>
<li><b>H.264</b>: Accumulated during CAVLC/CABAC decoding.</li>
<li><b>HEVC</b>: Accumulated during CABAC decoding in <span class="tt">hevcdec.c</span>.</li>
<li><b>VP9</b>: Accumulated during entropy decoding in <span class="tt">vp9mvs.c</span> for NEWMV mode blocks.</li>
<li><b>AV1</b>: Accumulated in modified libaom decoder using <span class="tt">aom_reader_tell_frac()</span> before and after <span class="tt">assign_mv()</span> calls in <span class="tt">read_inter_block_mode_info()</span> (<span class="tt">decodemv.c</span>). Stored in <span class="tt">pbi-&gt;motion_bits</span> and exposed through <span class="tt">insp_frame_data.motion_bits</span>. Note: Bit counts are in fractional bits (1/8th precision) during accumulation and converted to whole bits in <span class="tt">ifd_inspect()</span>.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md48"></a>
coefs_bit_count</h3>
<p>Number of bits used for coding transform coefficients in the frame. Unit: bits.</p>
<ul>
<li><b>H.264</b>: Accumulated during CAVLC/CABAC decoding.</li>
<li><b>HEVC</b>: Accumulated during CABAC decoding.</li>
<li><b>VP9</b>: Accumulated during frame decoding.</li>
<li><b>AV1</b>: Accumulated in modified libaom decoder using <span class="tt">aom_reader_tell_frac()</span> before and after coefficient reading calls in <span class="tt">decode_reconstruct_tx()</span> and intra block decoding loops (<span class="tt">decodeframe.c</span>). Stored in <span class="tt">td-&gt;coef_bits</span> (per thread) and exposed through <span class="tt">insp_frame_data.coef_bits</span>. Note: Bit counts are in fractional bits (1/8th precision) during accumulation and converted to whole bits in <span class="tt">ifd_inspect()</span>.</li>
</ul>
<h2 class="doxsection"><a class="anchor" id="autotoc_md49"></a>
Block Count Metrics</h2>
<h3 class="doxsection"><a class="anchor" id="autotoc_md50"></a>
mb_mv_count</h3>
<p>Number of macroblocks/coding units/blocks with motion vectors. Unit: count.</p>
<ul>
<li><b>H.264</b>: Incremented for each macroblock partition that uses inter prediction.</li>
<li><b>HEVC</b>: Incremented for each prediction unit (PU) with inter prediction.</li>
<li><b>VP9</b>: Incremented for each block with non-zero motion (excludes ZEROMV mode). Note: VP9 uses variable block sizes (4x4 to 64x64), so count depends on encoder block size decisions.</li>
<li><b>AV1</b>: Incremented for each MI (mode info) block with inter prediction (mode &gt;= NEARESTMV). Note: AV1 uses variable block sizes (4x4 to 128x128), so count is at MI resolution (4x4 units).</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md51"></a>
mv_coded_count</h3>
<p>Number of explicitly coded motion vectors (excluding predicted/derived MVs). Unit: count.</p>
<ul>
<li><b>H.264</b>: Counts MVs that are entropy-coded in the bitstream.</li>
<li><b>HEVC</b>: Counts MVs that are entropy-coded in the bitstream.</li>
<li><b>VP9</b>: Counts NEWMV mode blocks where motion delta is explicitly coded. NEARESTMV/NEARMV modes use predicted MVs and are not counted.</li>
<li><b>AV1</b>: Counts NEWMV mode blocks (including compound variants: NEW_NEWMV, NEAREST_NEWMV, NEW_NEARESTMV, NEAR_NEWMV, NEW_NEARMV). NEARESTMV/NEARMV/GLOBALMV modes use predicted MVs and are not counted.</li>
</ul>
<h2 class="doxsection"><a class="anchor" id="autotoc_md52"></a>
POC Metrics</h2>
<p>POC (Picture Order Count) is a frame ordering mechanism used in H.264 and HEVC to track the display order of frames independently from decode order.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md53"></a>
current_poc</h3>
<p>The Picture Order Count of the current frame. Unit: count (dimensionless).</p>
<ul>
<li><b>H.264</b>: Extracted from the decoded picture's POC value in <span class="tt">h264_slice.c</span>. POC values are computed according to the H.264 spec (types 0, 1, or 2) and can wrap at 65536. Values &gt; 32768 are adjusted to be negative for consistency.</li>
<li><b>HEVC</b>: Extracted from <span class="tt">s-&gt;poc</span> in <span class="tt">hevcdec.c</span> during <span class="tt">hevc_frame_start()</span>. POC is computed per the HEVC spec from <span class="tt">pic_order_cnt_lsb</span> in the slice header.</li>
<li><b>VP9</b>: Not applicable. VP9 does not use the POC concept. Always returns 0.</li>
<li><b>AV1</b>: Not applicable. AV1 does not use the POC concept. Always returns 0.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md54"></a>
poc_diff</h3>
<p>The minimum POC difference between consecutive frames. This represents the POC increment per frame and is useful for temporal normalization of motion vectors. Unit: count (dimensionless).</p>
<ul>
<li><b>H.264</b>: Calculated by tracking POC changes between frames. Uses PTS information when available for more accurate calculation (handles cases where frames are decoded out of order). Typical values: 1 or 2.</li>
<li><b>HEVC</b>: Same calculation method as H.264. Tracked in <span class="tt">hevc_frame_start()</span>. Typical values: 1 or 2.</li>
<li><b>VP9</b>: Not applicable. Always returns 0.</li>
<li><b>AV1</b>: Not applicable. Always returns 0.</li>
</ul>
<p><b>Note:</b> For the first frame, <span class="tt">poc_diff</span> is <span class="tt">-1</span> (sentinel value indicating "not yet calculated"). Starting from the second frame, the actual POC difference is computed and reported. Most encoders use a <span class="tt">poc_diff</span> of 1 or 2.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md55"></a>
Frame Metadata</h2>
<h3 class="doxsection"><a class="anchor" id="autotoc_md56"></a>
frame_type</h3>
<p>Type of the frame: 1 = I (Intra), 2 = P (Predicted), 3 = B (Bi-directional). Unit: enum.</p>
<ul>
<li><b>All codecs</b>: Extracted from frame header via ffmpeg's <span class="tt">pict_type</span>.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md57"></a>
frame_idx</h3>
<p>Zero-based index of the frame in decode order. Unit: count.</p>
<ul>
<li><b>All codecs</b>: Tracked by the parser during decoding.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md58"></a>
is_idr</h3>
<p>Whether the frame is an IDR (Instantaneous Decoder Refresh) frame. Unit: boolean.</p>
<ul>
<li><b>H.264</b>: True for NAL unit type 5.</li>
<li><b>HEVC</b>: True for IDR_W_RADL or IDR_N_LP NAL units.</li>
<li><b>VP9</b>: True for keyframes.</li>
<li><b>AV1</b>: True for keyframes.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md59"></a>
size</h3>
<p>Frame size. Unit: bytes.</p>
<ul>
<li><b>All codecs</b>: Extracted from packet size directly in ffmpeg.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md60"></a>
pts</h3>
<p>Presentation timestamp. Unit: seconds.</p>
<ul>
<li><b>All codecs</b>: Converted from ffmpeg's <span class="tt">pts</span> using stream time base.</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md61"></a>
dts</h3>
<p>Decoding timestamp. Unit: seconds.</p>
<ul>
<li><b>All codecs</b>: Converted from ffmpeg's <span class="tt">dts</span> using stream time base.</li>
</ul>
<h1 class="doxsection"><a class="anchor" id="autotoc_md62"></a>
Differences with Legacy Implementation</h1>
<p>This section documents intentional differences between videoparser-ng and the legacy <a href="https://github.com/Telecommunication-Telemedia-Assessment/bitstream_mode3_videoparser"><span class="tt">bitstream_mode3_videoparser</span></a> implementation. These changes were made to improve correctness, cross-codec consistency, and simplicity.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md63"></a>
All Codecs: POC-based Motion Vector Normalization</h2>
<p>The legacy implementation normalized motion vectors by temporal distance (POC difference) to reference frames:</p>
<div class="fragment"><div class="line"><span class="comment">// Legacy: MV values divided by temporal distance</span></div>
<div class="line">mvX /= (8 * FrmDist);</div>
<div class="line">NormFwd = 1.0 / (2.0 * fabs((CurrPOC - RefPOC) / POC_DIF));</div>
</div><!-- fragment --><p>videoparser-ng uses raw motion vector values without normalization. This provides:</p>
<ul>
<li>Simpler, more predictable output</li>
<li>Values that directly correspond to what's in the bitstream</li>
<li>Independence from GOP structure and reference frame selection</li>
</ul>
<p>If temporal normalization is needed, it can be applied as a post-processing step.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md64"></a>
VP9: Motion Statistics for All Inter Modes</h2>
<p>The legacy VP9 implementation only accumulated motion vector statistics for <span class="tt">NEWMV</span> mode blocks (explicitly coded motion deltas):</p>
<div class="fragment"><div class="line"><span class="comment">// Legacy VP9: Only NEWMV counted</span></div>
<div class="line"><span class="keywordflow">if</span> (b-&gt;mode[idx] == NEWMV) {</div>
<div class="line">    S-&gt;MV_Length += MV_LengthXY * count;</div>
<div class="line">    <span class="comment">// ...</span></div>
<div class="line">}</div>
</div><!-- fragment --><p>This was inconsistent with H.264/HEVC, which counted <b>all</b> inter blocks regardless of prediction mode.</p>
<p>videoparser-ng counts all inter modes (<span class="tt">NEARESTMV</span>, <span class="tt">NEARMV</span>, <span class="tt">NEWMV</span>) except <span class="tt">ZEROMV</span>, making VP9 behavior consistent with other codecs:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Codec  </th><th class="markdownTableHeadNone">Legacy MV Stats  </th><th class="markdownTableHeadNone">videoparser-ng MV Stats  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">H.264  </td><td class="markdownTableBodyNone">All inter blocks  </td><td class="markdownTableBodyNone">All inter blocks  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">HEVC  </td><td class="markdownTableBodyNone">All inter blocks  </td><td class="markdownTableBodyNone">All inter blocks  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">VP9  </td><td class="markdownTableBodyNone"><span class="tt">NEWMV</span> only  </td><td class="markdownTableBodyNone">All inter blocks (except <span class="tt">ZEROMV</span>)  </td></tr>
</table>
<h2 class="doxsection"><a class="anchor" id="autotoc_md65"></a>
VP9: Motion Bit Count</h2>
<p>The legacy implementation did not track <span class="tt">motion_bit_count</span> for VP9 (always returned 0).</p>
<p>videoparser-ng correctly tracks motion bits during VP9 entropy decoding.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md66"></a>
VP9: Removed Weighted Variance Accumulation</h2>
<p>The legacy VP9 implementation used <span class="tt">scount = count * count</span> when accumulating squared values for variance:</p>
<div class="fragment"><div class="line"><span class="comment">// Legacy: Inflated variance calculation</span></div>
<div class="line">scount = count * count;</div>
<div class="line">S-&gt;MV_SumSQR += SQR(MV_LengthXY) * scount;</div>
</div><!-- fragment --><p>videoparser-ng uses standard variance accumulation without the extra count multiplier, providing mathematically correct standard deviation values.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md67"></a>
All Codecs: Removed Arbitrary Scaling Factors</h2>
<p>The legacy implementation applied various scaling factors (e.g., <span class="tt">4.0 *</span> multiplier on MV lengths) that were likely historical artifacts.</p>
<p>videoparser-ng outputs unscaled values in native codec units (1/4 pel for H.264/HEVC, 1/8 pel for VP9/AV1).</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md68"></a>
Testing</h1>
<p>The test scripts use <a href="https://docs.astral.sh/uv/">uv</a> inline script metadata (PEP 723) for dependency management. This means you can run them directly without installing dependencies manually – <span class="tt">uv</span> will handle it automatically.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md69"></a>
Feature Testing</h2>
<p>The main test suite validates parser output against reference <span class="tt">.ldjson</span> files for all supported codecs (H.264, H.265, VP9, AV1):</p>
<div class="fragment"><div class="line"># Run with uv</div>
<div class="line">uv run test/test.py</div>
<div class="line"> </div>
<div class="line"># Or make executable and run directly</div>
<div class="line">chmod +x test/test.py</div>
<div class="line">./test/test.py</div>
<div class="line"> </div>
<div class="line"># Run specific codec test</div>
<div class="line">uv run test/test.py -k &quot;libx264&quot;</div>
</div><!-- fragment --><p>The test compares all frames in each test video against the expected output in the corresponding <span class="tt">.ldjson</span> file. Any differences are reported with a readable table showing expected vs actual values.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md70"></a>
Regenerating Test Reference Files</h2>
<p>If you intentionally change parser output (e.g., fixing a bug or adding a feature), regenerate the reference files:</p>
<div class="fragment"><div class="line"># Generate reference output for all test videos</div>
<div class="line">for video in test/test-lib*.mp4; do</div>
<div class="line">    base=$(basename &quot;$video&quot; .mp4)</div>
<div class="line">    build/VideoParserCli/video-parser &quot;$video&quot; &gt; &quot;test/${base}.ldjson&quot;</div>
<div class="line">done</div>
</div><!-- fragment --><h2 class="doxsection"><a class="anchor" id="autotoc_md71"></a>
Legacy Testing</h2>
<p>The legacy test suite compares against output from the original <a href="https://github.com/Telecommunication-Telemedia-Assessment/bitstream_mode3_videoparser"><span class="tt">bitstream_mode3_videoparser</span></a>. This is useful for verifying backwards compatibility or understanding intentional differences.</p>
<p>First, obtain the legacy test data:</p>
<div class="fragment"><div class="line">wget https://storage.googleapis.com/aveq-storage/data/videoparser-ng/test/test.zip -O test/legacy/test.zip</div>
<div class="line">unzip test/legacy/test.zip -d test/legacy</div>
</div><!-- fragment --><p>Then run the legacy tests:</p>
<div class="fragment"><div class="line">uv run test/legacy/test.py</div>
</div><!-- fragment --><p>Note: Some tests may fail due to intentional differences documented in Differences with Legacy Implementation.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md72"></a>
CLI Testing</h2>
<p>CLI tests validate command-line interface behavior:</p>
<div class="fragment"><div class="line">uv run test/test-cli.py</div>
</div><!-- fragment --><h1 class="doxsection"><a class="anchor" id="autotoc_md73"></a>
Debugging</h1>
<p>We have successfully used the following VS Code <span class="tt">launch.json</span> configuration to debug the CLI – it requires the <span class="tt">CMake Tools</span> extension:</p>
<div class="fragment"><div class="line">{</div>
<div class="line">  &quot;version&quot;: &quot;0.2.0&quot;,</div>
<div class="line">  &quot;configurations&quot;: [</div>
<div class="line">    {</div>
<div class="line">      &quot;name&quot;: &quot;(lldb) Launch&quot;,</div>
<div class="line">      &quot;type&quot;: &quot;cppdbg&quot;,</div>
<div class="line">      &quot;request&quot;: &quot;launch&quot;,</div>
<div class="line">      // Resolved by CMake Tools:</div>
<div class="line">      &quot;program&quot;: &quot;${command:cmake.launchTargetPath}&quot;,</div>
<div class="line">      &quot;args&quot;: [</div>
<div class="line">        // &quot;${workspaceFolder}/test/test_video_h264.mkv&quot;,</div>
<div class="line">        &quot;${workspaceFolder}/test/test_video_h265.mkv&quot;,</div>
<div class="line">      ],</div>
<div class="line">      // comment out the below if you want to set your own breakpoints!</div>
<div class="line">      &quot;stopAtEntry&quot;: true,</div>
<div class="line">      &quot;cwd&quot;: &quot;${workspaceFolder}/build&quot;,</div>
<div class="line">      &quot;environment&quot;: [</div>
<div class="line">        {</div>
<div class="line">          // add the directory where our target was built to the PATHs</div>
<div class="line">          // it gets resolved by CMake Tools:</div>
<div class="line">          &quot;name&quot;: &quot;PATH&quot;,</div>
<div class="line">          &quot;value&quot;: &quot;${env:PATH}:${command:cmake.getLaunchTargetDirectory}&quot;</div>
<div class="line">        }</div>
<div class="line">      ],</div>
<div class="line">      &quot;MIMode&quot;: &quot;lldb&quot;</div>
<div class="line">    }</div>
<div class="line">  ]</div>
<div class="line">}</div>
</div><!-- fragment --><p>Replace the <span class="tt">"${workspaceFolder}/test/test_video_h265.mkv"</span> with the path to the video you want to debug.</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md74"></a>
Maintenance</h1>
<h2 class="doxsection"><a class="anchor" id="autotoc_md75"></a>
Fetching new FFmpeg commits</h2>
<p>Occasionally you want to rebase your local FFmpeg commits on top of the latest upstream FFmpeg commits. This is done by running the dedicated script.</p>
<p>Run the script:</p>
<div class="fragment"><div class="line">util/rebase-ffmpeg.sh</div>
</div><!-- fragment --><p>The rebase may not be clean, so check the output of the script and resolve any conflicts.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md76"></a>
Fetching new libaom commits</h2>
<p>Similarly, you can rebase your local libaom commits on top of the latest upstream libaom commits.</p>
<p>Run the script:</p>
<div class="fragment"><div class="line">util/rebase-libaom.sh</div>
</div><!-- fragment --><p>The rebase may not be clean, so check the output of the script and resolve any conflicts.</p>
<h1 class="doxsection"><a class="anchor" id="autotoc_md77"></a>
Black Border Implementation Notes</h1>
<p>This section describes the black border detection algorithm and its possible integration into the QP statistics calculation.</p>
<p><span class="tt">Av_QPBB</span> is a computed statistic that represents the average Quantization Parameter (QP) of video content excluding black letterbox/pillarbox borders. This is important for video quality assessment because black borders typically have uniform, easily-encodable content with artificially low or high QP values that would skew the "true" content QP measurement.</p>
<p>The legacy code developer's key observation was that black border regions in widescreen/letterboxed videos contain mostly zero-coefficient INTRA blocks. Since pure black areas have no texture or motion, encoders typically:</p>
<ol type="1">
<li>Use INTRA prediction (DC or planar modes)</li>
<li>Generate nearly all-zero residual coefficients after transform</li>
</ol>
<p>By counting rows that have a high proportion of such "empty" blocks, the algorithm can estimate where borders exist.</p>
<h2 class="doxsection"><a class="anchor" id="autotoc_md78"></a>
Algorithm Details</h2>
<h2 class="doxsection"><a class="anchor" id="autotoc_md79"></a>
1. BlackLine Array Population (Per-Codec)</h2>
<p>During decoding, a BlackLine[] array is populated where each entry counts zero-coefficient blocks in that row.</p>
<p>H.264 (VideoStat264.c:160-185)</p>
<div class="fragment"><div class="line"><span class="comment">// Only on I-frames</span></div>
<div class="line"><span class="keywordflow">for</span>( j = 0, NonZeroCoefs=0 ; j&lt;16 ; NonZeroCoefs += NZC_Table[sl-&gt;mb_xy][j++] ) ;</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span>( (MbType &amp; MB_TYPE_INTRA4x4) || (MbType &amp; MB_TYPE_INTRA16x16) )</div>
<div class="line">{</div>
<div class="line">  <span class="keywordflow">if</span>( !Cbp_Table[sl-&gt;mb_xy] &amp;&amp; (NonZeroCoefs == 0) )</div>
<div class="line">    Ctx-&gt;BlackLine[sl-&gt;mb_y]++ ;  <span class="comment">// Increment count for this row</span></div>
<div class="line">}</div>
</div><!-- fragment --><p>Uses non_zero_count and cbp_table from H.264 decoder to identify INTRA macroblocks with no coded coefficients.</p>
<p>H.265/HEVC (VideoStatHEVC.c:345-364)</p>
<div class="fragment"><div class="line"><span class="comment">// Only on I-frames</span></div>
<div class="line"><span class="keywordflow">for</span>( tuy = 0 ; tuy &lt; sps-&gt;min_tb_height ; tuy++ )</div>
<div class="line">  <span class="keywordflow">for</span>( tux = 0 ; tux &lt; sps-&gt;min_tb_width ; tux++ )</div>
<div class="line">    <span class="keywordflow">if</span>( cbf_luma[tuy*sps-&gt;min_tb_width + tux] == 0 )</div>
<div class="line">      BlackLine[tuy]++ ;</div>
</div><!-- fragment --><p>Uses the cbf_luma (Coded Block Flag for luma) array to identify transform units with no coded coefficients.</p>
<p>VP9 (VideoStatVP9.c:376-381)</p>
<div class="fragment"><div class="line"><span class="comment">// Count 4x4 columns with zero-tx</span></div>
<div class="line"><span class="keywordflow">if</span> (sum == 0)</div>
<div class="line">  <span class="keywordflow">for</span>( j = y; j &lt; y + step ; j++ )</div>
<div class="line">    s-&gt;BlackLine[2 * row + j] += step ;</div>
</div><!-- fragment --><p>Sums transform coefficients; if sum is zero, increments the BlackLine counter.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md80"></a>
2. Black Border Detection (VideoStatCommon.c:12-31)</h3>
<div class="fragment"><div class="line"><span class="keywordtype">int</span> BlackborderDetect( <span class="keywordtype">int</span>* BlackLine, <span class="keywordtype">int</span> rows, <span class="keywordtype">int</span> threshold, <span class="keywordtype">int</span> logBlkSize )</div>
<div class="line">{</div>
<div class="line">  <span class="keywordtype">int</span> BlackLines = 0, i;</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Step 1: Symmetry enforcement - combine top and bottom</span></div>
<div class="line">  <span class="keywordflow">for</span>( i = 0 ; i &lt; rows&gt;&gt;1 ; i++ )</div>
<div class="line">    BlackLine[i] = BlackLine[rows-i-1] =</div>
<div class="line">      ((BlackLine[i] + BlackLine[rows-i-1]) &gt;= (threshold &lt;&lt; 1)) ? 1 : 0 ;</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Step 2: Count consecutive &quot;black&quot; rows from top</span></div>
<div class="line">  <span class="keywordflow">for</span>( i = 0 ; i &lt; rows ; i++ )</div>
<div class="line">  {</div>
<div class="line">    <span class="keywordflow">if</span>( BlackLine[i] != 0 )</div>
<div class="line">      BlackLines++ ;</div>
<div class="line">    <span class="keywordflow">else</span></div>
<div class="line">      break ;</div>
<div class="line">  }</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Step 3: Sanity check - reject if &gt; 50% of frame</span></div>
<div class="line">  <span class="keywordflow">if</span>( BlackLines &gt;= (rows &gt;&gt; 1) )</div>
<div class="line">    BlackLines = 0 ;</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Step 4: Convert block rows to pixels</span></div>
<div class="line">  <span class="keywordflow">return</span>( BlackLines &lt;&lt; logBlkSize ) ;</div>
<div class="line">}</div>
</div><!-- fragment --><p>Key Algorithm Steps:</p>
<ol type="1">
<li>Symmetry Enforcement: Assumes letterboxing is symmetric (top = bottom). Combines counts from row i and row rows-i-1. If combined count exceeds 2 × threshold, marks row as "black" (1), else not black (0).</li>
<li>Consecutive Count: Counts consecutive rows from the top that are marked as black. Stops at first non-black row.</li>
<li>Sanity Check: If detected black lines exceed 50% of frame height, rejects detection (returns 0). This prevents false positives from mostly-dark content.</li>
<li>Pixel Conversion: Multiplies block count by block size (1 &lt;&lt; logBlkSize) to get pixel height.</li>
</ol>
<h3 class="doxsection"><a class="anchor" id="autotoc_md81"></a>
3. Threshold Values (Codec-Specific)</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Codec  </th><th class="markdownTableHeadNone">Threshold  </th><th class="markdownTableHeadNone">Block Size  </th><th class="markdownTableHeadNone">Rationale  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">H.264  </td><td class="markdownTableBodyNone">0.8 × mb_width  </td><td class="markdownTableBodyNone">16×16 (logBlkSize=4)  </td><td class="markdownTableBodyNone">80% of macroblocks in row must be zero  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">H.265  </td><td class="markdownTableBodyNone">0.72 × min_tb_width  </td><td class="markdownTableBodyNone">Variable (log2_min_tb_size)  </td><td class="markdownTableBodyNone">72% of transform blocks must be zero  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">VP9  </td><td class="markdownTableBodyNone">1.2 × cols  </td><td class="markdownTableBodyNone">4×4 (logBlkSize=2)  </td><td class="markdownTableBodyNone">120% accounts for 8×8 grid with sub-blocks  </td></tr>
</table>
<p>TODO: Why were these specific thresholds chosen? Possibly empirical tuning.</p>
<h3 class="doxsection"><a class="anchor" id="autotoc_md82"></a>
4. QP Statistics with Border Exclusion</h3>
<p>Determining if Block is in Border (VideoStat264.c:308)</p>
<div class="fragment"><div class="line">NoBorder = ((sl-&gt;mb_y &lt;&lt; 4) &gt;= FrmStat-&gt;BlackBorder) &amp;&amp;</div>
<div class="line">            ((sl-&gt;mb_y &lt;&lt; 4) &lt; (h-&gt;height - FrmStat-&gt;BlackBorder));</div>
</div><!-- fragment --><p>Accumulating QP (VideoStatCommon.c:38-56)</p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> QPStatistics( VIDEO_STAT* FrmStat, <span class="keywordtype">int</span> CurrQP, <span class="keywordtype">int</span> CurrType, <span class="keywordtype">int</span> NoBorder )</div>
<div class="line">{</div>
<div class="line">  <span class="comment">// Always accumulate (with border)</span></div>
<div class="line">  S-&gt;QpSum += CurrQP ;</div>
<div class="line">  S-&gt;QpSumSQ += SQR( CurrQP ) ;</div>
<div class="line">  S-&gt;QpCnt++ ;</div>
<div class="line"> </div>
<div class="line">  <span class="comment">// Only accumulate for non-border blocks (BB = &quot;Black Border&quot; excluded)</span></div>
<div class="line">  <span class="keywordflow">if</span>( NoBorder )</div>
<div class="line">  {</div>
<div class="line">    S-&gt;QpSumBB += CurrQP ;</div>
<div class="line">    S-&gt;QpSumSQBB += SQR( CurrQP ) ;</div>
<div class="line">    S-&gt;QpCntBB++ ;</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><h3 class="doxsection"><a class="anchor" id="autotoc_md83"></a>
5. Final Computation (VideoStatCommon.c:165-171)</h3>
<div class="fragment"><div class="line">FrmStat-&gt;Av_QPBB     = S-&gt;QpSumBB / (double)S-&gt;QpCntBB ;</div>
<div class="line">FrmStat-&gt;StdDev_QPBB = sqrt( S-&gt;QpSumSQBB / (<span class="keywordtype">double</span>)S-&gt;QpCntBB -</div>
<div class="line">                              SQR( S-&gt;QpSumBB / (<span class="keywordtype">double</span>)S-&gt;QpCntBB ) ) ;</div>
</div><!-- fragment --><p>Mathematical Formulas:</p>
<ul>
<li>Av_QPBB = Σ(QP for blocks outside black border) / Count</li>
<li>StdDev_QPBB = √(Var) = √(E[QP²] - E[QP]²)</li>
</ul>
<h3 class="doxsection"><a class="anchor" id="autotoc_md84"></a>
FFmpeg Modifications</h3>
<p>Modified Files:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">File  </th><th class="markdownTableHeadNone">Purpose  </th><th class="markdownTableHeadNone">Marker  </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">ffmpeg/libavutil/internal.h:357  </td><td class="markdownTableBodyNone">Declares extern int CurrBlackBorder  </td><td class="markdownTableBodyNone">P.L.  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">ffmpeg/libavcodec/h264_slice.c:50-51  </td><td class="markdownTableBodyNone">Function declarations  </td><td class="markdownTableBodyNone">P.L.  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">ffmpeg/libavcodec/h264_slice.c:2417  </td><td class="markdownTableBodyNone">Calls InitFrameStatistics264() at slice start  </td><td class="markdownTableBodyNone">P.L.  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">ffmpeg/libavcodec/h264_slice.c:2591  </td><td class="markdownTableBodyNone">Calls BlackborderDetect() at end of I-frame  </td><td class="markdownTableBodyNone">P.L.  </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">ffmpeg/libavcodec/hevc.c:2385  </td><td class="markdownTableBodyNone">Calls BlackBorderEstimationHEVC() at frame end  </td><td class="markdownTableBodyNone">P.L.  </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">ffmpeg/libavcodec/hevc.h:1078  </td><td class="markdownTableBodyNone">Function declaration  </td><td class="markdownTableBodyNone">P.L.  </td></tr>
</table>
<p>Key Integration Points:</p>
<ol type="1">
<li>H.264 (h264_slice.c:2590-2591): At the finish: label after slice decoding:</li>
<li>HEVC (hevc.c:2385): After CTB (Coding Tree Block) processing:</li>
<li>VP9 (VideoStatVP9.c:476): At frame statistics finalization:</li>
</ol>
<h3 class="doxsection"><a class="anchor" id="autotoc_md85"></a>
Design Decisions</h3>
<ol type="1">
<li>Only I-frames trigger recalculation: Black border detection only happens on I-frames (or keyframes for VP9). P/B frames inherit the previous CurrBlackBorder value. This is because:<ul>
<li>I-frames have complete INTRA prediction making zero-coefficient detection reliable</li>
<li>Scene changes (where borders might change) typically occur at I-frames</li>
<li>Reduces computational overhead</li>
</ul>
</li>
<li>Global CurrBlackBorder variable: Persists across frames to maintain border detection between I-frames.</li>
<li>Symmetric assumption: The algorithm enforces symmetry between top and bottom borders, which is typical for letterboxed content but would fail for asymmetric borders (rare in practice).</li>
<li>Spatial complexity usage (VideoStatCommon.c:175): <span class="tt">FrmStat-&gt;SpatialComplexety[0] = BpF *exp( 0.115524* FrmStat-&gt;Av_QPBB );</span> </li>
</ol>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<div id="page-nav" class="page-nav-panel">
<div id="page-nav-resize-handle"></div>
<div id="page-nav-tree">
<div id="page-nav-contents">
</div><!-- page-nav-contents -->
</div><!-- page-nav-tree -->
</div><!-- page-nav -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.15.0 </li>
  </ul>
</div>
</body>
</html>
